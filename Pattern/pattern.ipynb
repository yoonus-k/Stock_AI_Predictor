{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Price Pattern Mining and Analysis\n",
    "\n",
    "This notebook focuses on extracting, analyzing, and storing meaningful price patterns from financial time series data. It demonstrates:\n",
    "\n",
    "1. Setting up the environment and importing required modules\n",
    "2. Loading stock price data from CSV files\n",
    "3. Storing data in a SQLite database\n",
    "4. Mining perceptually important points (PIPs) from price data\n",
    "5. Clustering similar patterns\n",
    "6. Analyzing pattern performance\n",
    "\n",
    "The Pattern_Miner class is used to identify key patterns in stock price movements and analyze their predictive power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to sqlite cloud database\n",
      "Environment setup complete\n"
     ]
    }
   ],
   "source": [
    "# System imports for path handling\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Configure Python path to allow imports from parent directory\n",
    "current_dir = Path(os.getcwd())\n",
    "project_root = current_dir.parent  # Stock_AI_Predictor root directory\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Data processing imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine learning imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Custom modules\n",
    "from Pattern.pip_pattern_miner import Pattern_Miner\n",
    "from Data.Database.db_cloud import Database\n",
    "\n",
    "# Initialize database connection\n",
    "db = Database()\n",
    "\n",
    "# Print confirmation of successful imports\n",
    "print(\"Environment setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Data Configuration\n",
    "\n",
    "Defining the stocks and timeframes to be analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary mapping stock IDs to names and ticker symbols\n",
    "companies = {\n",
    "    1: \"GOLD (XAUUSD)\",   # Gold spot price\n",
    "    2: \"BTC (BTCUSD)\",    # Bitcoin\n",
    "    3: \"APPL (AAPL)\",     # Apple Inc.\n",
    "    4: \"Amazon (AMZN)\",   # Amazon.com Inc.\n",
    "    5: \"NVIDIA (NVDA)\",   # NVIDIA Corporation\n",
    "}\n",
    "\n",
    "# Dictionary mapping timeframe IDs to minute values\n",
    "time_frames = {\n",
    "    1: 15,  # 15-minute intervals\n",
    "    2: 60,  # 1-hour intervals\n",
    "}\n",
    "\n",
    "print(f\"Configured {len(companies)} stocks and {len(time_frames)} timeframes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Processing\n",
    "\n",
    "This section handles:\n",
    "1. Reading stock data from CSV files\n",
    "2. Processing and cleaning the data\n",
    "3. Storing the processed data in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m     time_frame_15 \u001b[38;5;241m=\u001b[39m time_frames[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     36\u001b[0m     time_frame_60 \u001b[38;5;241m=\u001b[39m time_frames[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m---> 37\u001b[0m     \u001b[43mprocess_stock_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstock_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_frame_15\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     process_stock_data(stock_id, symbol, time_frame_60)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll stocks processed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 25\u001b[0m, in \u001b[0;36mprocess_stock_data\u001b[1;34m(stock_id, symbol, time_frame)\u001b[0m\n\u001b[0;32m     22\u001b[0m     df_original \u001b[38;5;241m=\u001b[39m df_original\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2019-01-01\u001b[39m\u001b[38;5;124m'\u001b[39m:]\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# Store the data\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m     \u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore_stock_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_original\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstock_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mticker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_frame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\yoonus\\Documents\\GitHub\\Stock_AI_Predictor\\Data\\db.py:82\u001b[0m, in \u001b[0;36mDatabase.store_stock_data\u001b[1;34m(self, stock_data, stock_ID, stock_symbol, time_frame)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (index, row) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(stock_data\u001b[38;5;241m.\u001b[39miterrows(), start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m     81\u001b[0m     time_Stamp \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 82\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'''\u001b[39;49m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;124;43m        INSERT INTO stock_data (StockEntryID, StockID, StockSymbol, Timestamp,TimeFrame ,OpenPrice, ClosePrice, HighPrice, LowPrice, Volume)\u001b[39;49m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;124;43m        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\u001b[39;49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;124;43m'''\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstock_ID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstock_symbol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_Stamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOpen\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mClose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHigh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLow\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mVolume\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# commit the changes\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection\u001b[38;5;241m.\u001b[39mcommit()\n",
      "File \u001b[1;32mc:\\Users\\yoonus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlitecloud\\dbapi2.py:277\u001b[0m, in \u001b[0;36mConnection.execute\u001b[1;34m(self, sql, parameters)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03mShortcut for cursor.execute().\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;124;03mSee the docstring of Cursor.execute() for more information.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;124;03m    Cursor: The cursor object.\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    276\u001b[0m cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcursor()\n\u001b[1;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yoonus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlitecloud\\dbapi2.py:583\u001b[0m, in \u001b[0;36mCursor.execute\u001b[1;34m(self, sql, parameters)\u001b[0m\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(parameters, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    581\u001b[0m     parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_named_to_question_mark_parameters(sql, parameters)\n\u001b[1;32m--> 583\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_driver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_statement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    584\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqlitecloud_connection\u001b[49m\n\u001b[0;32m    585\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resultset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result_operation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yoonus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlitecloud\\driver.py:109\u001b[0m, in \u001b[0;36mDriver.execute_statement\u001b[1;34m(self, query, bindings, connection)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;124;03mExecute the statement on the SQLite Cloud server.\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03mIt supports only the `qmark` style for parameter binding.\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    105\u001b[0m command \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_serialize_command(\n\u001b[0;32m    106\u001b[0m     [query] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(bindings), zero_string\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    107\u001b[0m )\n\u001b[1;32m--> 109\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_run_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mtag \u001b[38;5;241m!=\u001b[39m SQLITECLOUD_RESULT_TYPE\u001b[38;5;241m.\u001b[39mRESULT_ARRAY:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\yoonus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlitecloud\\driver.py:482\u001b[0m, in \u001b[0;36mDriver._internal_run_command\u001b[1;34m(self, connection, command, main_socket)\u001b[0m\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SQLiteCloudException(\n\u001b[0;32m    477\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe connection is closed.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    478\u001b[0m         SQLITECLOUD_INTERNAL_ERRCODE\u001b[38;5;241m.\u001b[39mNETWORK,\n\u001b[0;32m    479\u001b[0m     )\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_socket_write(connection, command, main_socket)\n\u001b[1;32m--> 482\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_socket_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmain_socket\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yoonus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlitecloud\\driver.py:535\u001b[0m, in \u001b[0;36mDriver._internal_socket_read\u001b[1;34m(self, connection, main_socket)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    534\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 535\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    536\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[0;32m    537\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m SQLiteCloudException(\n\u001b[0;32m    538\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncomplete response from server. Cannot read the command length.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    539\u001b[0m             )\n",
      "File \u001b[1;32mc:\\Users\\yoonus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1233\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1230\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1231\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1232\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[1;32mc:\\Users\\yoonus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1106\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[0;32m   1108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def process_stock_data(stock_id, symbol, time_frame):\n",
    "    \"\"\"\n",
    "    Process stock data from CSV files and store in database.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    stock_id : int\n",
    "        ID of the stock in the database\n",
    "    symbol : str\n",
    "        Stock symbol in format 'Name (TICKER)'\n",
    "    time_frame : int\n",
    "        Time frame in minutes (e.g., 15, 60)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    bool\n",
    "        True if processing and storage successful, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract the ticker symbol from the format \"Name (TICKER)\"\n",
    "        ticker = symbol.split('(')[-1].replace(')', '').strip()\n",
    "        \n",
    "        # Construct file path relative to project root\n",
    "        file_path = f\"../Data/Raw/Stocks/{ticker}{time_frame}.csv\"\n",
    "        print(f\"Loading data from {file_path}\")\n",
    "        \n",
    "        # Read and process the data\n",
    "        df_original = pd.read_csv(file_path)\n",
    "        \n",
    "        # Create datetime index by combining date and time\n",
    "        df_original['Date'] = pd.to_datetime(df_original['Date'] + ' ' + df_original['Time'])\n",
    "        df_original['Date'] = df_original['Date'].astype('datetime64[s]')  # Standardize datetime format\n",
    "        df_original = df_original.set_index('Date')\n",
    "        \n",
    "        # Drop the time column as it's now part of the index\n",
    "        df_original = df_original.drop(columns=['Time'])\n",
    "        \n",
    "        # Clean data by removing any NaN values\n",
    "        df_original = df_original.dropna()\n",
    "        \n",
    "        # Filter data to include only from 2019 onwards\n",
    "        df_original = df_original.loc['2019-01-01':]\n",
    "        \n",
    "        # Store the processed data in the database\n",
    "        rows_stored = db.store_stock_data(df_original, stock_id, ticker, time_frame)\n",
    "        print(f\"Stored {rows_stored} rows for {ticker} ({time_frame}m)\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found for {symbol} (ID: {stock_id}) with timeframe {time_frame}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {symbol} (ID: {stock_id}): {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Process all companies with both timeframes\n",
    "successful_imports = 0\n",
    "failed_imports = 0\n",
    "\n",
    "for stock_id, symbol in companies.items():\n",
    "    # Process 15-minute data\n",
    "    if process_stock_data(stock_id, symbol, time_frames[1]):\n",
    "        successful_imports += 1\n",
    "    else:\n",
    "        failed_imports += 1\n",
    "        \n",
    "    # Process 60-minute (hourly) data\n",
    "    if process_stock_data(stock_id, symbol, time_frames[2]):\n",
    "        successful_imports += 1\n",
    "    else:\n",
    "        failed_imports += 1\n",
    "\n",
    "print(f\"Data processing complete: {successful_imports} successful, {failed_imports} failed imports.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern Mining and Clustering\n",
    "\n",
    "This section identifies important patterns in price data using the Pattern_Miner class, which:\n",
    "1. Extracts perceptually important points (PIPs) from price series\n",
    "2. Groups similar patterns using clustering techniques\n",
    "3. Analyzes historical performance of each pattern cluster\n",
    "4. Stores patterns and clusters in the database for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing GOLD (XAUUSD) (ID: 1) with timeframe 60...\n",
      "Data split - Train: (29693,), Test: (7424,)\n",
      "Successfully processed patterns for GOLD (XAUUSD) (ID: 1) with timeframe 60.\n",
      "\n",
      "Processing BTC (BTCUSD) (ID: 2) with timeframe 60...\n",
      "Data split - Train: (38004,), Test: (9502,)\n",
      "Successfully processed patterns for BTC (BTCUSD) (ID: 2) with timeframe 60.\n",
      "\n",
      "Processing APPL (AAPL) (ID: 3) with timeframe 60...\n",
      "Data split - Train: (8804,), Test: (2202,)\n",
      "Successfully processed patterns for APPL (AAPL) (ID: 3) with timeframe 60.\n",
      "\n",
      "Processing Amazon (AMZN) (ID: 4) with timeframe 60...\n",
      "Data split - Train: (8804,), Test: (2202,)\n",
      "Successfully processed patterns for Amazon (AMZN) (ID: 4) with timeframe 60.\n",
      "\n",
      "Processing NVIDIA (NVDA) (ID: 5) with timeframe 60...\n",
      "Data split - Train: (8804,), Test: (2202,)\n",
      "Successfully processed patterns for NVIDIA (NVDA) (ID: 5) with timeframe 60.\n",
      "Closed connection to database: ../Data/data.db\n",
      "\n",
      "Pattern mining completed for all stocks.\n"
     ]
    }
   ],
   "source": [
    "def perform_pattern_mining_for_all_stocks(n_pips=5, lookback=24, hold_period=6, returns_hold_period=12, time_frame=60):\n",
    "    \"\"\"\n",
    "    Perform pattern mining and clustering for all stocks in the database.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_pips : int\n",
    "        Number of perceptually important points to identify (default: 5)\n",
    "    lookback : int\n",
    "        Window size for pattern identification in candles (default: 24)\n",
    "    hold_period : int\n",
    "        Period to hold after pattern identification for outcome calculation (default: 6)\n",
    "    returns_hold_period : int\n",
    "        Extended period for calculating maximum gain/drawdown (default: 12)\n",
    "    time_frame : int\n",
    "        Time frame in minutes to use for analysis (default: 60)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Track processing statistics\n",
    "    successful_processing = 0\n",
    "    failed_processing = 0\n",
    "    \n",
    "    for stock_id, symbol in companies.items():\n",
    "        try:\n",
    "            print(f\"\\nProcessing {symbol} (ID: {stock_id}) with timeframe {time_frame} minutes...\")\n",
    "            \n",
    "            # Fetch stock data from database\n",
    "            df = db.get_stock_data(stock_id, time_frame)\n",
    "            \n",
    "            if df.empty:\n",
    "                print(f\"No data found for {symbol} (ID: {stock_id})\")\n",
    "                failed_processing += 1\n",
    "                continue\n",
    "                \n",
    "            # Extract close prices for pattern mining\n",
    "            arr = df['ClosePrice'].to_numpy()\n",
    "            \n",
    "            # Split data into train and test sets (80/20 split)\n",
    "            train, test = train_test_split(arr, test_size=0.2, shuffle=False)\n",
    "            print(f\"Data split - Train: {train.shape}, Test: {test.shape}\")\n",
    "            \n",
    "            # Create and train the pattern miner\n",
    "            pip_miner = Pattern_Miner(n_pips, lookback, hold_period, returns_hold_period)\n",
    "            pip_miner.train(train)\n",
    "            \n",
    "            # Print pattern mining results\n",
    "            num_patterns = len(pip_miner._unique_pip_patterns)\n",
    "            num_clusters = len(pip_miner._cluster_centers)\n",
    "            print(f\"Found {num_patterns} unique patterns grouped into {num_clusters} clusters\")\n",
    "            \n",
    "            # Store the patterns and clusters in the database\n",
    "            db.pip_pattern_miner = pip_miner\n",
    "            \n",
    "            # Store patterns with their properties\n",
    "            patterns_stored = db.store_pattern_data(stock_id, pip_miner)\n",
    "            print(f\"Stored {patterns_stored} patterns in database\")\n",
    "            \n",
    "            # Store clusters with their aggregated properties\n",
    "            clusters_stored = db.store_cluster_data(stock_id, pip_miner)\n",
    "            print(f\"Stored {clusters_stored} clusters in database\")\n",
    "            \n",
    "            # Associate patterns with their respective clusters\n",
    "            db.bind_pattern_cluster(stock_id, pip_miner)\n",
    "            \n",
    "            # Calculate and update probability scores for all clusters\n",
    "            db.update_all_cluster_probability_score(stock_id, pip_miner)\n",
    "            \n",
    "            print(f\"Successfully processed patterns for {symbol} (ID: {stock_id})\")\n",
    "            successful_processing += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {symbol} (ID: {stock_id}): {str(e)}\")\n",
    "            failed_processing += 1\n",
    "    \n",
    "    # Close database connection\n",
    "    db.close()\n",
    "    print(f\"\\nPattern mining completed: {successful_processing} successful, {failed_processing} failed.\")\n",
    "\n",
    "# Run pattern mining with default parameters\n",
    "print(\"Starting pattern mining process...\")\n",
    "perform_pattern_mining_for_all_stocks(n_pips=5, lookback=24, hold_period=6, returns_hold_period=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split Date Ranges\n",
    "\n",
    "This section calculates the appropriate date ranges for training and testing data, which is useful for backtesting and model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dates: (Timestamp('2019-01-02 01:00:00'), Timestamp('2024-01-08 01:00:00'))\n",
      "Test Dates: (Timestamp('2024-01-09 01:00:00'), Timestamp('2025-04-10 23:00:00'))\n"
     ]
    }
   ],
   "source": [
    "def get_test_train_dates(stock_id, time_frame):\n",
    "    \"\"\"\n",
    "    Determine the date ranges for training and testing datasets.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    stock_id : int\n",
    "        ID of the stock in the database\n",
    "    time_frame : int\n",
    "        Time frame in minutes\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        ((train_start, train_end), (test_start, test_end)) date ranges\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Reconnect to database if needed\n",
    "        if not hasattr(db, '_conn') or db._conn is None:\n",
    "            db = Database()\n",
    "            \n",
    "        # Fetch stock data from database\n",
    "        df = db.get_stock_data(stock_id, time_frame)\n",
    "        \n",
    "        if df.empty:\n",
    "            print(f\"No data found for stock ID: {stock_id}\")\n",
    "            return None, None\n",
    "        \n",
    "        # Get the first and last dates of the dataset\n",
    "        start_date = df.index[0]\n",
    "        end_date = df.index[-1]\n",
    "        \n",
    "        # Split the data into train (80%) and test (20%) sets\n",
    "        train_start_date = start_date\n",
    "        train_end_date = start_date + pd.DateOffset(days=int((end_date - start_date).days * 0.8))\n",
    "        test_start_date = train_end_date + pd.DateOffset(days=1)\n",
    "        test_end_date = end_date\n",
    "        \n",
    "        # Format dates for readability\n",
    "        train_range = (train_start_date.strftime('%Y-%m-%d'), train_end_date.strftime('%Y-%m-%d'))\n",
    "        test_range = (test_start_date.strftime('%Y-%m-%d'), test_end_date.strftime('%Y-%m-%d'))\n",
    "        \n",
    "        return train_range, test_range\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching dates for stock ID {stock_id}: {str(e)}\")\n",
    "        return None, None\n",
    "    \n",
    "# Get train/test date ranges for GOLD (XAUUSD) with 1-hour timeframe\n",
    "train_dates, test_dates = get_test_train_dates(1, 60)\n",
    "\n",
    "if train_dates and test_dates:\n",
    "    print(f\"Training data period: {train_dates[0]} to {train_dates[1]}\")\n",
    "    print(f\"Testing data period: {test_dates[0]} to {test_dates[1]}\")\n",
    "    \n",
    "    # Calculate duration in days\n",
    "    train_start = pd.to_datetime(train_dates[0])\n",
    "    train_end = pd.to_datetime(train_dates[1])\n",
    "    test_start = pd.to_datetime(test_dates[0])\n",
    "    test_end = pd.to_datetime(test_dates[1])\n",
    "    \n",
    "    train_days = (train_end - train_start).days\n",
    "    test_days = (test_end - test_start).days\n",
    "    \n",
    "    print(f\"Training duration: {train_days} days ({train_days/365:.1f} years)\")\n",
    "    print(f\"Testing duration: {test_days} days ({test_days/365:.1f} years)\")\n",
    "else:\n",
    "    print(\"Could not retrieve date ranges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern Visualization and Analysis\n",
    "\n",
    "This section demonstrates how to visualize patterns and analyze their performance. It retrieves patterns from the database and shows their shapes, distributions, and predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_pattern_clusters(stock_id=1, time_frame=60, num_clusters_to_show=5):\n",
    "    \"\"\"\n",
    "    Visualize pattern clusters from the database.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    stock_id : int\n",
    "        ID of the stock to visualize patterns for\n",
    "    time_frame : int\n",
    "        Time frame in minutes\n",
    "    num_clusters_to_show : int\n",
    "        Number of clusters to display\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Reconnect to database if needed\n",
    "        if not hasattr(db, '_conn') or db._conn is None:\n",
    "            db = Database()\n",
    "            \n",
    "        # Get cluster data from database\n",
    "        clusters = db.get_clusters(stock_id, time_frame=time_frame)\n",
    "        \n",
    "        if clusters.empty or len(clusters) == 0:\n",
    "            print(f\"No clusters found for stock ID {stock_id}\")\n",
    "            return\n",
    "            \n",
    "        # Limit the number of clusters to display\n",
    "        clusters_to_show = min(num_clusters_to_show, len(clusters))\n",
    "        \n",
    "        # Set up the figure\n",
    "        fig, axs = plt.subplots(clusters_to_show, 2, figsize=(14, 3*clusters_to_show))\n",
    "        \n",
    "        # Display each cluster\n",
    "        for i in range(clusters_to_show):\n",
    "            # Get cluster data\n",
    "            cluster = clusters.iloc[i]\n",
    "            price_points = np.array(cluster['AVGPricePoints'])\n",
    "            \n",
    "            # Plot the pattern shape\n",
    "            axs[i, 0].plot(price_points, marker='o')\n",
    "            axs[i, 0].set_title(f\"Cluster {i+1}: {cluster['Label']}\")\n",
    "            axs[i, 0].grid(True)\n",
    "            axs[i, 0].set_xlabel('Time Steps')\n",
    "            axs[i, 0].set_ylabel('Normalized Price')\n",
    "            \n",
    "            # Plot expected outcome\n",
    "            outcome = float(cluster['Outcome'])\n",
    "            probability = float(cluster['ProbabilityScore']) if 'ProbabilityScore' in cluster else 0.5\n",
    "            colors = ['red' if outcome < 0 else 'green']\n",
    "            axs[i, 1].bar(['Return'], [outcome*100], color=colors)\n",
    "            axs[i, 1].set_title(f\"Expected Return: {outcome*100:.2f}% (Probability: {probability:.2f})\")\n",
    "            axs[i, 1].set_ylabel('Percentage Return')\n",
    "            axs[i, 1].grid(True)\n",
    "            axs[i, 1].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error visualizing patterns: {str(e)}\")\n",
    "\n",
    "# Visualize patterns for GOLD (XAUUSD) on 1-hour timeframe\n",
    "print(\"Visualizing pattern clusters for GOLD (XAUUSD)...\")\n",
    "visualize_pattern_clusters(stock_id=1, time_frame=60, num_clusters_to_show=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "This notebook has demonstrated the complete workflow for stock pattern mining:\n",
    "\n",
    "1. **Data Preparation**: Loading and processing stock data from CSV files\n",
    "2. **Pattern Mining**: Identifying perceptually important points in price series\n",
    "3. **Pattern Clustering**: Grouping similar patterns to find recurring market behaviors\n",
    "4. **Performance Analysis**: Analyzing the predictive power of each pattern cluster\n",
    "5. **Database Integration**: Storing all patterns, clusters, and analyses for later use\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Use the patterns for trading strategy development\n",
    "2. Implement real-time pattern detection for live trading\n",
    "3. Expand the analysis to include more technical indicators\n",
    "4. Incorporate sentiment analysis to enhance pattern predictive power\n",
    "5. Develop an automated backtesting system to evaluate pattern-based strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up and close database connection\n",
    "try:\n",
    "    db.close()\n",
    "    print(\"Database connection closed successfully\")\n",
    "except:\n",
    "    print(\"Database already closed or connection error\")\n",
    "\n",
    "print(\"Pattern analysis notebook completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
