{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afb23388",
   "metadata": {},
   "source": [
    "# Stock AI Predictor - Google Colab Runner\n",
    "\n",
    "This notebook allows you to run Stock AI Predictor models on Google Colab with minimal setup. It handles:\n",
    "- Setting up the environment\n",
    "- Connecting to Google Drive\n",
    "- Transferring database files\n",
    "- Running parameter testing and pattern mining scripts\n",
    "\n",
    "**Date:** May 15, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfc3cdd",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "1. Upload your `data.db` file to your Google Drive\n",
    "2. Run this notebook cell by cell\n",
    "3. Adjust the path to your database file in the database setup section\n",
    "4. Make sure all dependencies are installed correctly\n",
    "5. Run the desired model scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139fb2cb",
   "metadata": {},
   "source": [
    "## Database Path Configuration\n",
    "\n",
    "The `setup_db_path` function ensures we can properly configure the database path dynamically for both local and Colab environments. This is crucial for maintaining code compatibility across different execution contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8629059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to set up database path dynamically for both local and Colab environments\n",
    "def setup_db_path():\n",
    "    \"\"\"\n",
    "    Configure database path based on environment\n",
    "    \n",
    "    This function detects whether we're running in Colab and sets up the correct\n",
    "    database path accordingly. It should be used in any script that needs to\n",
    "    access the database.\n",
    "    \n",
    "    Returns:\n",
    "        str: The correct path to the database file\n",
    "    \"\"\"\n",
    "    import os\n",
    "    \n",
    "    # Check if we're running in Colab\n",
    "    in_colab = 'google.colab' in str(get_ipython())\n",
    "    \n",
    "    if in_colab:\n",
    "        # When in Colab, use the standard path\n",
    "        db_path = \"./Data/Storage/data.db\"\n",
    "    else:\n",
    "        # When running locally, use the regular path\n",
    "        # Get the current working directory\n",
    "        cwd = os.getcwd()\n",
    "        \n",
    "        # Check if we're in a subdirectory of the project\n",
    "        if os.path.basename(cwd) == 'Colab':\n",
    "            db_path = \"../Data/Storage/data.db\"\n",
    "        else:\n",
    "            db_path = \"./Data/Storage/data.db\"\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(os.path.dirname(db_path), exist_ok=True)\n",
    "    \n",
    "    return db_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6a32f3",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ea3ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyDrive for Google Drive integration\n",
    "!pip install -q pydrive2\n",
    "\n",
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "print(\"Google Drive mounted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c519c160",
   "metadata": {},
   "source": [
    "## 2. Repository Setup\n",
    "\n",
    "There are two options to get the code:\n",
    "1. Clone directly from GitHub\n",
    "2. Upload from your Drive if you already have it there\n",
    "\n",
    "Choose the most appropriate option for your workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76232b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Clone from GitHub\n",
    "# Uncomment and modify with your own repository URL if needed\n",
    "# !git clone https://github.com/yourusername/Stock_AI_Predictor.git\n",
    "# %cd Stock_AI_Predictor\n",
    "\n",
    "# Option 2: Copy from Google Drive (if you have it there)\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define source path in your Google Drive\n",
    "drive_repo_path = \"/content/drive/MyDrive/Stock_AI_Predictor\"  # Update this path\n",
    "local_repo_path = \"/content/Stock_AI_Predictor\"\n",
    "\n",
    "# Create directory for local repository\n",
    "os.makedirs(local_repo_path, exist_ok=True)\n",
    "\n",
    "# Function to copy directory contents recursively\n",
    "def copy_directory(src, dst):\n",
    "    for item in os.listdir(src):\n",
    "        s = os.path.join(src, item)\n",
    "        d = os.path.join(dst, item)\n",
    "        if os.path.isdir(s):\n",
    "            os.makedirs(d, exist_ok=True)\n",
    "            copy_directory(s, d)\n",
    "        else:\n",
    "            shutil.copy2(s, d)\n",
    "\n",
    "# Copy repository from Drive to Colab if it exists\n",
    "if os.path.exists(drive_repo_path):\n",
    "    copy_directory(drive_repo_path, local_repo_path)\n",
    "    print(f\"Repository copied from Google Drive to {local_repo_path}\")\n",
    "else:\n",
    "    print(f\"Repository not found at {drive_repo_path}. Please check the path or use git clone.\")\n",
    "\n",
    "# Change to repository directory\n",
    "%cd /content/Stock_AI_Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c98e56d",
   "metadata": {},
   "source": [
    "## 3. Install Dependencies\n",
    "\n",
    "Install all required packages for Stock AI Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7333e703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install all required dependencies\n",
    "!pip install -r Colab/requirements.txt\n",
    "\n",
    "# Verify key packages are installed\n",
    "import pkg_resources\n",
    "import pandas as pd\n",
    "\n",
    "key_packages = ['numpy', 'pandas', 'scikit-learn', 'tensorflow', 'torch', 'yfinance', 'sqlitecloud']\n",
    "for package in key_packages:\n",
    "    try:\n",
    "        version = pkg_resources.get_distribution(package).version\n",
    "        print(f\"{package}: {version}\")\n",
    "    except pkg_resources.DistributionNotFound:\n",
    "        print(f\"{package}: Not installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82c2b2e",
   "metadata": {},
   "source": [
    "## 4. Database Setup\n",
    "\n",
    "Copy and set up the database file from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a65fe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define paths (adjust these according to your Drive structure)\n",
    "drive_db_path = \"/content/drive/MyDrive/Stock_AI_Predictor/data.db\"  # Update this path\n",
    "local_db_dir = \"./Data/Storage/\"\n",
    "local_db_path = os.path.join(local_db_dir, \"data.db\")\n",
    "\n",
    "# Create directory structure if it doesn't exist\n",
    "os.makedirs(local_db_dir, exist_ok=True)\n",
    "os.makedirs(\"./Data/Raw/Stocks\", exist_ok=True)\n",
    "os.makedirs(\"./Data/Raw/Sentiment\", exist_ok=True)\n",
    "\n",
    "# Copy database file\n",
    "if os.path.exists(drive_db_path):\n",
    "    shutil.copy(drive_db_path, local_db_path)\n",
    "    print(f\"Database copied from {drive_db_path} to {local_db_path}\")\n",
    "    \n",
    "    # Verify database file\n",
    "    if os.path.exists(local_db_path):\n",
    "        print(f\"Database size: {os.path.getsize(local_db_path) / (1024*1024):.2f} MB\")\n",
    "    else:\n",
    "        print(\"Database copy failed. Check file permissions.\")\n",
    "else:\n",
    "    print(f\"Warning: Database file not found at {drive_db_path}\")\n",
    "    print(\"You'll need to create or download a new database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03531739",
   "metadata": {},
   "source": [
    "## Database Path Patching\n",
    "\n",
    "This section applies necessary patches to ensure the database connections work correctly in the Colab environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedab0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the database patcher to ensure compatibility\n",
    "from Colab.colab_db_helper import setup_database\n",
    "from Colab.colab_db_patcher import patch_all_db_files\n",
    "\n",
    "# Define path to your database in Google Drive\n",
    "drive_db_path = \"/content/drive/MyDrive/Stock_AI_Predictor/data.db\"  # Update this path\n",
    "\n",
    "# Setup the database (copy from Drive to local storage)\n",
    "db_setup_success = setup_database(drive_db_path)\n",
    "\n",
    "# Patch database-related files if setup was successful\n",
    "if db_setup_success:\n",
    "    patched_files = patch_all_db_files()\n",
    "    print(f\"Successfully patched {patched_files} database-related files\")\n",
    "else:\n",
    "    print(\"Database setup failed. Check the paths and permissions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfeb3bd3",
   "metadata": {},
   "source": [
    "## 5. Path Configuration\n",
    "\n",
    "Set up Python path to include the project modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137fee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add current directory to path so Python can find the modules\n",
    "sys.path.append('.')\n",
    "\n",
    "# Test importing modules to verify project structure\n",
    "try:\n",
    "    from Core import engine_v2\n",
    "    print(\"Core module imported successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing project modules: {e}\")\n",
    "    print(\"Check that the project structure is correct.\")\n",
    "\n",
    "# Verify important directories exist\n",
    "important_dirs = ['Core', 'Data', 'Colab', 'Pattern', 'RL', 'Sentiment']\n",
    "for dir_name in important_dirs:\n",
    "    if os.path.isdir(dir_name):\n",
    "        print(f\"✓ {dir_name} directory found\")\n",
    "    else:\n",
    "        print(f\"✗ {dir_name} directory NOT found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cafdc3",
   "metadata": {},
   "source": [
    "## 6. Database Connection Test\n",
    "\n",
    "Verify that we can connect to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b987c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Test database connection\n",
    "try:\n",
    "    conn = sqlite3.connect(local_db_path)\n",
    "    # Get list of tables\n",
    "    tables = pd.read_sql_query(\"SELECT name FROM sqlite_master WHERE type='table';\", conn)\n",
    "    print(\"Database tables:\")\n",
    "    for table in tables['name']:\n",
    "        print(f\"- {table}\")\n",
    "    conn.close()\n",
    "    print(\"\\nDatabase connection successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"Database connection error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdccf0f",
   "metadata": {},
   "source": [
    "## Run Models\n",
    "\n",
    "Now that the environment is set up, you can run the various models and scripts. Uncomment the cells below to run specific models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f4b14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run parameter tester (multi-threaded version)\n",
    "try:\n",
    "    print(\"Running multi-threaded parameter tester...\")\n",
    "    %run Colab/parameter_tester_multithreaded.py\n",
    "    print(\"Parameter testing completed successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error running parameter tester: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e24efb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run pattern miner (uncomment to run)\n",
    "'''\n",
    "try:\n",
    "    print(\"Running PIP pattern miner...\")\n",
    "    %run Colab/pip_pattern_miner.py\n",
    "    print(\"Pattern mining completed successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error running pattern miner: {e}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b806ad02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run standard parameter tester (uncomment to run)\n",
    "'''\n",
    "try:\n",
    "    print(\"Running standard parameter tester...\")\n",
    "    %run Colab/parameter_tester.py\n",
    "    print(\"Standard parameter testing completed successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error running standard parameter tester: {e}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ff2b58",
   "metadata": {},
   "source": [
    "## Save Results\n",
    "\n",
    "After running the models, you can save the results back to Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7e584b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results back to Google Drive\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to copy directory recursively\n",
    "def copy_directory(src, dst):\n",
    "    if not os.path.exists(dst):\n",
    "        os.makedirs(dst)\n",
    "    for item in os.listdir(src):\n",
    "        s = os.path.join(src, item)\n",
    "        d = os.path.join(dst, item)\n",
    "        if os.path.isdir(s):\n",
    "            copy_directory(s, d)\n",
    "        else:\n",
    "            if not os.path.exists(os.path.dirname(d)):\n",
    "                os.makedirs(os.path.dirname(d))\n",
    "            shutil.copy2(s, d)\n",
    "\n",
    "# Create a timestamped directory for results\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "drive_results_dir = f\"/content/drive/MyDrive/Stock_AI_Predictor/Results_{timestamp}\"\n",
    "os.makedirs(drive_results_dir, exist_ok=True)\n",
    "\n",
    "# Define directories to save\n",
    "dirs_to_save = [\n",
    "    \"Images\",           # Save generated images\n",
    "    \"Data/Storage\",     # Save updated database\n",
    "    \"Experements\"       # Save experiment results\n",
    "]\n",
    "\n",
    "# Copy each directory to Google Drive\n",
    "for dir_path in dirs_to_save:\n",
    "    src_path = os.path.join(\".\", dir_path)\n",
    "    dst_path = os.path.join(drive_results_dir, dir_path)\n",
    "    \n",
    "    if os.path.exists(src_path):\n",
    "        # Copy directory\n",
    "        try:\n",
    "            copy_directory(src_path, dst_path)\n",
    "            print(f\"Copied {src_path} to Google Drive\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error copying {src_path}: {e}\")\n",
    "    else:\n",
    "        print(f\"Directory not found: {src_path}\")\n",
    "\n",
    "print(f\"\\nAll results saved to Google Drive at: {drive_results_dir}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
