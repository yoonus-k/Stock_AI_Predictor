{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f193e179",
   "metadata": {},
   "source": [
    "# Stock AI Predictor - Parameter Testing on Google Colab\n",
    "\n",
    "This notebook runs parameter testing for stock prediction patterns using Google Colab's high-performance environment. It's designed to handle computationally intensive parameter combinations, especially for short timeframes like 1-minute data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831437c1",
   "metadata": {},
   "source": [
    "## 0. Check Environment and Install Dependencies\n",
    "\n",
    "First, let's check if we're in Colab and install any needed packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d94256c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify we're in Colab\n",
    "import sys\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print(f\"Running in Colab: {IN_COLAB}\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Install critical dependencies for pattern mining and data analysis\n",
    "    print(\"Installing dependencies...\")\n",
    "    !pip install mplfinance pyclustering matplotlib seaborn pandas numpy scikit-learn tqdm bcrypt sqlitecloud python-dotenv\n",
    "else:\n",
    "    print(\"Not running in Colab - skipping package installation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df11840",
   "metadata": {},
   "source": [
    "## 1. Setup Environment\n",
    "\n",
    "First, let's mount Google Drive and install required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ce9985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd773d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository if not already in Drive\n",
    "!git clone https://github.com/YOUR_USERNAME/Stock_AI_Predictor.git /content/Stock_AI_Predictor\n",
    "\n",
    "# Or use existing repository from Drive\n",
    "# !ln -s /content/drive/MyDrive/Stock_AI_Predictor /content/Stock_AI_Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b08d381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify critical imports are working\n",
    "def check_import(module_name):\n",
    "    \"\"\"Try importing a module and report success/failure\"\"\"\n",
    "    try:\n",
    "        __import__(module_name)\n",
    "        return True\n",
    "    except ImportError as e:\n",
    "        return False\n",
    "\n",
    "critical_modules = [\n",
    "    \"mplfinance\", \n",
    "    \"pyclustering\", \n",
    "    \"matplotlib\", \n",
    "    \"numpy\", \n",
    "    \"pandas\", \n",
    "    \"sklearn\",\n",
    "    \"tqdm\",\n",
    "    \"sqlitecloud\"\n",
    "]\n",
    "\n",
    "# Check all modules\n",
    "for module in critical_modules:\n",
    "    result = \"✓ Available\" if check_import(module) else \"✗ Missing - will install\"\n",
    "    print(f\"{module:15}: {result}\")\n",
    "\n",
    "# Install any missing modules\n",
    "for module in critical_modules:\n",
    "    if not check_import(module):\n",
    "        print(f\"Installing {module}...\")\n",
    "        !pip install {module} -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8d6ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -r /content/Stock_AI_Predictor/requirements.txt\n",
    "!pip install tqdm bcrypt sqlitecloud python-dotenv mplfinance pyclustering matplotlib seaborn pandas numpy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414c3e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Colab-specific requirements if available\n",
    "colab_req_path = '/content/Stock_AI_Predictor/NoteBook/colab_requirements.txt'\n",
    "\n",
    "# Create the requirements file if it doesn't exist\n",
    "if not os.path.exists(colab_req_path):\n",
    "    print(\"Creating Colab-specific requirements file...\")\n",
    "    %%writefile {colab_req_path}\n",
    "    # Colab parameter testing requirements\n",
    "    # Data processing\n",
    "    pandas>=1.3.0\n",
    "    numpy>=1.20.0\n",
    "    # Visualization\n",
    "    matplotlib>=3.4.0\n",
    "    seaborn>=0.11.0\n",
    "    mplfinance>=0.12.7b0\n",
    "    # Pattern mining\n",
    "    pyclustering>=0.10.1\n",
    "    scikit-learn>=1.0.0\n",
    "    # Database\n",
    "    sqlitecloud\n",
    "    bcrypt\n",
    "    # Utilities\n",
    "    tqdm\n",
    "    python-dotenv\n",
    "\n",
    "# Install the Colab-specific requirements\n",
    "print(\"Installing Colab-specific requirements...\")\n",
    "!pip install -r {colab_req_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5afc46",
   "metadata": {},
   "source": [
    "## 2. Upload Database to Colab\n",
    "\n",
    "### Option 1: Upload from local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d775a54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "# Create directory for database\n",
    "!mkdir -p /content/Stock_AI_Predictor/Data/Storage\n",
    "\n",
    "# Upload database file\n",
    "uploaded = files.upload()\n",
    "for filename in uploaded.keys():\n",
    "    # Move uploaded file to the correct location\n",
    "    !mv \"{filename}\" \"/content/Stock_AI_Predictor/Data/Storage/data.db\"\n",
    "    print(f\"Uploaded {filename} to /content/Stock_AI_Predictor/Data/Storage/data.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fa904a",
   "metadata": {},
   "source": [
    "### Option 2: Copy from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2c348f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Specify the source path in Google Drive\n",
    "drive_db_path = '/content/drive/MyDrive/Stock_AI_Predictor/Data/Storage/data.db'\n",
    "\n",
    "# Destination path in Colab\n",
    "colab_db_path = '/content/Stock_AI_Predictor/Data/Storage/data.db'\n",
    "\n",
    "# Ensure directory exists\n",
    "os.makedirs(os.path.dirname(colab_db_path), exist_ok=True)\n",
    "\n",
    "# Copy the file\n",
    "if os.path.exists(drive_db_path):\n",
    "    shutil.copy(drive_db_path, colab_db_path)\n",
    "    print(f\"Database copied from Drive to {colab_db_path}\")\n",
    "else:\n",
    "    print(f\"Database not found at {drive_db_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62421be",
   "metadata": {},
   "source": [
    "### Option 3: Connect to SQLite Cloud (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b01b365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create .env file with SQLite Cloud credentials\n",
    "%%writefile /content/Stock_AI_Predictor/.env\n",
    "SQLITECLOUD_URL=\"your_sqlitecloud_connection_string_here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880cc24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy and create the colab_helpers.py file to the Colab environment\n",
    "%%writefile /content/Stock_AI_Predictor/NoteBook/colab_helpers.py\n",
    "# Helper functions for Google Colab environment\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import shutil\n",
    "from typing import Optional, Dict, Tuple, List\n",
    "\n",
    "def setup_colab_environment():\n",
    "    \"\"\"\n",
    "    Set up the Colab environment for Stock AI Predictor parameter testing\n",
    "    Returns the correct database path and ensures necessary directories exist\n",
    "    \"\"\"\n",
    "    # Base paths\n",
    "    project_root = '/content/Stock_AI_Predictor'\n",
    "    drive_root = '/content/drive/MyDrive/Stock_AI_Predictor'\n",
    "    \n",
    "    # Check if we're using Drive or local storage\n",
    "    using_drive = os.path.exists('/content/drive/MyDrive')\n",
    "    \n",
    "    if using_drive:\n",
    "        print(\"Using Google Drive for storage\")\n",
    "        # Make sure Drive directories exist\n",
    "        os.makedirs(f\"{drive_root}/Data/Storage\", exist_ok=True)\n",
    "        os.makedirs(f\"{drive_root}/Images/ParamTesting\", exist_ok=True)\n",
    "        os.makedirs(f\"{drive_root}/docs\", exist_ok=True)\n",
    "        \n",
    "        # Create the local directories too\n",
    "        os.makedirs(f\"{project_root}/Data/Storage\", exist_ok=True)\n",
    "        \n",
    "        # Check if DB exists in Drive\n",
    "        drive_db_path = f\"{drive_root}/Data/Storage/data.db\"\n",
    "        local_db_path = f\"{project_root}/Data/Storage/data.db\"\n",
    "        \n",
    "        if os.path.exists(drive_db_path):\n",
    "            print(f\"Found database in Drive: {drive_db_path}\")\n",
    "            # Copy to local if needed\n",
    "            if not os.path.exists(local_db_path):\n",
    "                print(f\"Copying database to local storage...\")\n",
    "                shutil.copy(drive_db_path, local_db_path)\n",
    "            return local_db_path\n",
    "        else:\n",
    "            print(f\"No database found in Drive. Will use local path: {local_db_path}\")\n",
    "            return local_db_path\n",
    "    else:\n",
    "        print(\"Google Drive not mounted. Using local storage only.\")\n",
    "        # Ensure local directory exists\n",
    "        os.makedirs(f\"{project_root}/Data/Storage\", exist_ok=True)\n",
    "        return f\"{project_root}/Data/Storage/data.db\"\n",
    "\n",
    "def check_critical_imports():\n",
    "    \"\"\"\n",
    "    Check all critical imports needed for parameter testing\n",
    "    Returns True if all imports succeed, False otherwise\n",
    "    \"\"\"\n",
    "    critical_modules = [\n",
    "        \"mplfinance\", \n",
    "        \"pyclustering\", \n",
    "        \"matplotlib\", \n",
    "        \"numpy\", \n",
    "        \"pandas\", \n",
    "        \"sklearn\",\n",
    "        \"tqdm\",\n",
    "        \"sqlitecloud\"\n",
    "    ]\n",
    "    \n",
    "    missing_modules = []\n",
    "    for module in critical_modules:\n",
    "        try:\n",
    "            __import__(module)\n",
    "            print(f\"✓ {module:15} available\")\n",
    "        except ImportError:\n",
    "            print(f\"✗ {module:15} missing\")\n",
    "            missing_modules.append(module)\n",
    "    \n",
    "    # Install missing modules\n",
    "    for module in missing_modules:\n",
    "        print(f\"Installing {module}...\")\n",
    "        os.system(f\"pip install {module} -q\")\n",
    "    \n",
    "    return len(missing_modules) == 0\n",
    "\n",
    "def check_pattern_miner_imports():\n",
    "    \"\"\"\n",
    "    Check imports specifically for Pattern_Miner\n",
    "    \"\"\"\n",
    "    pip_pattern_file = '/content/Stock_AI_Predictor/Pattern/pip_pattern_miner.py'\n",
    "    \n",
    "    if not os.path.exists(pip_pattern_file):\n",
    "        print(\"Could not find pip_pattern_miner.py at expected location!\")\n",
    "        os.system(\"find /content/Stock_AI_Predictor -name 'pip_pattern_miner.py'\")\n",
    "        return False\n",
    "        \n",
    "    print(\"Checking pip_pattern_miner.py imports...\")\n",
    "    os.system(f\"head -10 {pip_pattern_file}\")\n",
    "    \n",
    "    # Try importing modules used by pip_pattern_miner\n",
    "    modules_to_check = [\n",
    "        \"mplfinance\", \n",
    "        \"pyclustering.cluster.silhouette\", \n",
    "        \"pyclustering.cluster.kmeans\",\n",
    "        \"pyclustering.cluster.center_initializer\",\n",
    "        \"sklearn.preprocessing\"\n",
    "    ]\n",
    "    \n",
    "    success = True\n",
    "    for module in modules_to_check:\n",
    "        try:\n",
    "            if \".\" in module:\n",
    "                parent = module.split(\".\")[0]\n",
    "                importlib.import_module(parent)\n",
    "            else:\n",
    "                importlib.import_module(module)\n",
    "            print(f\"✓ Successfully imported {module}\")\n",
    "        except ImportError as e:\n",
    "            print(f\"✗ Failed to import {module}: {e}\")\n",
    "            # Try to install the module\n",
    "            simple_name = module.split(\".\")[0] \n",
    "            print(f\"  Installing {simple_name}...\")\n",
    "            os.system(f\"pip install {simple_name} -q\")\n",
    "            success = False\n",
    "            \n",
    "    return success\n",
    "\n",
    "def setup_python_path():\n",
    "    \"\"\"Ensure the project root is in the Python path\"\"\"\n",
    "    project_root = '/content/Stock_AI_Predictor'\n",
    "    \n",
    "    if project_root not in sys.path:\n",
    "        sys.path.insert(0, project_root)\n",
    "        print(f\"Added {project_root} to Python path\")\n",
    "    \n",
    "    # Print the Python path to confirm\n",
    "    print(\"Python path includes:\")\n",
    "    for p in sys.path:\n",
    "        print(f\"  {p}\")\n",
    "    \n",
    "    return project_root in sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32752568",
   "metadata": {},
   "source": [
    "## 3. Import and Run Parameter Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2317915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the project root to sys.path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Ensure the project root is in the path\n",
    "sys.path.insert(0, '/content/Stock_AI_Predictor')\n",
    "\n",
    "# Try to import and use the colab helpers if available\n",
    "try:\n",
    "    from NoteBook.colab_helpers import setup_colab_environment, check_critical_imports, check_pattern_miner_imports, setup_python_path\n",
    "    \n",
    "    # First ensure Python path is set correctly\n",
    "    setup_python_path()\n",
    "    \n",
    "    # Check critical imports are available\n",
    "    print(\"\\nChecking critical imports:\")\n",
    "    check_critical_imports()\n",
    "    \n",
    "    # Check pattern miner imports specifically\n",
    "    print(\"\\nChecking Pattern Miner imports:\")\n",
    "    check_pattern_miner_imports()\n",
    "    \n",
    "    print(\"Successfully used helper functions\")\n",
    "except ImportError:\n",
    "    # Fallback to manual setup\n",
    "    print(\"Helper functions not available, using manual setup\")\n",
    "    \n",
    "    # Print the Python path to confirm\n",
    "    print(\"Python path includes:\")\n",
    "    for p in sys.path:\n",
    "        print(f\"  {p}\")\n",
    "\n",
    "# Now try importing the parameter tester\n",
    "print(\"\\nImporting ColabParameterTester:\")\n",
    "try:\n",
    "    # Try importing the module\n",
    "    from Experements.ParamTesting.colab_parameter_tester import ColabParameterTester\n",
    "    print(\"✓ Successfully imported ColabParameterTester\")\n",
    "except ModuleNotFoundError as e:\n",
    "    # If the module isn't found, print details and try to fix\n",
    "    print(f\"✗ Import error: {e}\")\n",
    "    module_name = str(e).split(\"'\")[-2]\n",
    "    print(f\"  Installing missing module: {module_name}\")\n",
    "    !pip install {module_name} -q\n",
    "    \n",
    "    # Try import again\n",
    "    try:\n",
    "        from Experements.ParamTesting.colab_parameter_tester import ColabParameterTester\n",
    "        print(\"✓ Successfully imported ColabParameterTester after installing dependencies\")\n",
    "    except Exception as e2:\n",
    "        print(f\"✗ Still having issues: {e2}\")\n",
    "        \n",
    "        # Try printing the import error in more detail\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    # Try import again\n",
    "    try:\n",
    "        from Experements.ParamTesting.colab_parameter_tester import ColabParameterTester\n",
    "        print(\"Successfully imported ColabParameterTester after installing dependencies\")\n",
    "    except Exception as e2:\n",
    "        print(f\"Still having issues: {e2}\")\n",
    "        print(\"Importing pip_pattern_miner directly to check dependencies:\")\n",
    "        !cat /content/Stock_AI_Predictor/Pattern/pip_pattern_miner.py | head -10\n",
    "except Exception as other_error:\n",
    "    print(f\"Unexpected error: {other_error}\")\n",
    "    print(\"Checking if pip_pattern_miner.py exists:\")\n",
    "    !ls -la /content/Stock_AI_Predictor/Pattern/\n",
    "\n",
    "# Use helper function to get correct database path if available\n",
    "try:\n",
    "    # Try to use the helper function if available\n",
    "    db_path = setup_colab_environment()\n",
    "    print(f\"Using database path from helper: {db_path}\")\n",
    "except NameError:\n",
    "    # Fallback to default path\n",
    "    db_path = '/content/Stock_AI_Predictor/Data/Storage/data.db'\n",
    "    print(f\"Using default database path: {db_path}\")\n",
    "    \n",
    "# Create directories if needed\n",
    "os.makedirs(os.path.dirname(db_path), exist_ok=True)\n",
    "\n",
    "# Create tester instance with the correct path\n",
    "try:\n",
    "    tester = ColabParameterTester(db_path=db_path)\n",
    "    print(\"Successfully created ColabParameterTester instance\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating tester: {e}\")\n",
    "    \n",
    "    # Try to diagnose the issue\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6dd21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and fix Pattern module imports if needed\n",
    "import importlib\n",
    "import os\n",
    "\n",
    "pip_pattern_file = '/content/Stock_AI_Predictor/Pattern/pip_pattern_miner.py'\n",
    "\n",
    "if os.path.exists(pip_pattern_file):\n",
    "    print(\"Checking pip_pattern_miner.py imports...\")\n",
    "    !head -10 {pip_pattern_file}\n",
    "    \n",
    "    # Try importing modules used by pip_pattern_miner\n",
    "    modules_to_check = [\n",
    "        \"mplfinance\", \n",
    "        \"pyclustering.cluster.silhouette\", \n",
    "        \"pyclustering.cluster.kmeans\",\n",
    "        \"pyclustering.cluster.center_initializer\",\n",
    "        \"sklearn.preprocessing\"\n",
    "    ]\n",
    "    \n",
    "    for module in modules_to_check:\n",
    "        try:\n",
    "            if \".\" in module:\n",
    "                parent = module.split(\".\")[0]\n",
    "                importlib.import_module(parent)\n",
    "            else:\n",
    "                importlib.import_module(module)\n",
    "            print(f\"✓ Successfully imported {module}\")\n",
    "        except ImportError as e:\n",
    "            print(f\"✗ Failed to import {module}: {e}\")\n",
    "            # Try to install the module\n",
    "            simple_name = module.split(\".\")[0] \n",
    "            print(f\"  Installing {simple_name}...\")\n",
    "            !pip install {simple_name} -q\n",
    "else:\n",
    "    print(\"Could not find pip_pattern_miner.py at expected location!\")\n",
    "    # Try to locate the file in case path is different\n",
    "    !find /content/Stock_AI_Predictor -name \"pip_pattern_miner.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3ccebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available stock and timeframe options\n",
    "stocks = tester.list_stocks()\n",
    "timeframes = tester.list_timeframes()\n",
    "\n",
    "print(\"Available stocks:\")\n",
    "for stock_id, stock_name in stocks:\n",
    "    print(f\"  {stock_id}: {stock_name}\")\n",
    "    \n",
    "print(\"\\nAvailable timeframes:\")\n",
    "for tf_id, tf_name in timeframes:\n",
    "    print(f\"  {tf_id}: {tf_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931f6fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Parameter Tests - Choose One of the Options Below\n",
    "\n",
    "## Option 1: Run for a specific stock and timeframe with date range\n",
    "import datetime\n",
    "\n",
    "# Set date range for testing (optional)\n",
    "start_date = \"2022-01-01\"  # Can be None to use all available data\n",
    "end_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")  # Use today as end date or None\n",
    "\n",
    "# Run the test and collect the results\n",
    "results, report = tester.run_parameter_testing_for_stock_timeframe_parallel(\n",
    "    \"GOLD\", \"M1\", \n",
    "    start_date=start_date, \n",
    "    end_date=end_date\n",
    ")\n",
    "\n",
    "## Option 2: Run a quick test (comment out Option 1 if you want to use this)\n",
    "# results = tester.run_quick_test(\"GOLD\", \"M1\")\n",
    "\n",
    "## Option 3: Compare hold period strategies (comment out Options 1 & 2 if you want to use this)\n",
    "# results = tester.compare_hold_period_strategies(\"GOLD\", \"M1\")\n",
    "\n",
    "## Option 4: Run all tests for multiple timeframes (comment out Options 1-3 if you want to use this)\n",
    "# all_results = tester.run_all_tests(stock_symbol=\"GOLD\")\n",
    "\n",
    "# Display top 5 parameter combinations if results exist\n",
    "if results is not None and not isinstance(results, dict):\n",
    "    print(\"\\nTop 5 parameter combinations:\")\n",
    "    print(results.head(5))\n",
    "elif results is not None and isinstance(results, dict):\n",
    "    print(\"\\nResults for multiple timeframes:\")\n",
    "    for tf, res in results.items():\n",
    "        if not res.empty:\n",
    "            print(f\"\\n{tf} - Top 3 combinations:\")\n",
    "            print(res.head(3))\n",
    "\n",
    "# Check GPU status during execution\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f420018",
   "metadata": {},
   "source": [
    "## 4. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da029229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and display visualization\n",
    "if 'results' in locals() and results is not None and not isinstance(results, dict):\n",
    "    # For single timeframe results\n",
    "    fig = tester.visualize_results(results, \"GOLD\", \"M1\")\n",
    "elif 'results' in locals() and results is not None and isinstance(results, dict):\n",
    "    # For multiple timeframe results\n",
    "    for tf, res in results.items():\n",
    "        if not res.empty:\n",
    "            print(f\"\\nVisualizing results for {tf}:\")\n",
    "            fig = tester.visualize_results(res, \"GOLD\", tf)\n",
    "            \n",
    "# If all_results exists (from Option 4)\n",
    "elif 'all_results' in locals() and all_results is not None:\n",
    "    for tf, res in all_results.items():\n",
    "        if not res.empty:\n",
    "            print(f\"\\nVisualizing results for {tf}:\")\n",
    "            fig = tester.visualize_results(res, \"GOLD\", tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831bde8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate optimization report\n",
    "if 'report' in locals() and report is not None:\n",
    "    # If we already have a report from previous execution\n",
    "    print(report)\n",
    "elif 'results' in locals() and results is not None and not isinstance(results, dict):\n",
    "    # For single timeframe results\n",
    "    report = tester.generate_report(results, \"GOLD\", \"M1\")\n",
    "    print(report)\n",
    "elif 'results' in locals() and results is not None and isinstance(results, dict):\n",
    "    # For multiple timeframe results\n",
    "    for tf, res in results.items():\n",
    "        if not res.empty:\n",
    "            report = tester.generate_report(res, \"GOLD\", tf)\n",
    "            print(f\"\\nReport for {tf}:\")\n",
    "            print(report)\n",
    "            \n",
    "# If all_results exists (from Option 4)\n",
    "elif 'all_results' in locals() and all_results is not None:\n",
    "    for tf, res in all_results.items():\n",
    "        if not res.empty:\n",
    "            report = tester.generate_report(res, \"GOLD\", tf)\n",
    "            print(f\"\\nReport for {tf}:\")\n",
    "            print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e331c1b",
   "metadata": {},
   "source": [
    "## 5. Save Results Back to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b597fe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the updated database back to Google Drive\n",
    "# This ensures your work is persisted\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Source path in Colab\n",
    "colab_db_path = '/content/Stock_AI_Predictor/Data/Storage/data.db'\n",
    "\n",
    "# Destination path in Google Drive\n",
    "drive_db_dir = '/content/drive/MyDrive/Stock_AI_Predictor/Data/Storage'\n",
    "os.makedirs(drive_db_dir, exist_ok=True)\n",
    "drive_db_path = os.path.join(drive_db_dir, 'data.db')\n",
    "\n",
    "# Copy the file\n",
    "shutil.copy(colab_db_path, drive_db_path)\n",
    "print(f\"Updated database saved to {drive_db_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1d6a2a",
   "metadata": {},
   "source": [
    "## 6. Save Report and Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9493b078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save report to a file\n",
    "import os\n",
    "\n",
    "def save_report(report_content, timeframe):\n",
    "    \"\"\"Helper function to save a report to Google Drive\"\"\"\n",
    "    if report_content:\n",
    "        report_path = f'/content/drive/MyDrive/Stock_AI_Predictor/docs/parameter_optimization_report_{timeframe}.md'\n",
    "        os.makedirs(os.path.dirname(report_path), exist_ok=True)\n",
    "        with open(report_path, 'w') as f:\n",
    "            f.write(report_content)\n",
    "        print(f\"Report saved to {report_path}\")\n",
    "\n",
    "# Save reports based on what data we have\n",
    "if 'report' in locals() and report is not None:\n",
    "    # If we have a single report\n",
    "    save_report(report, \"M1\")  # Adjust timeframe as needed\n",
    "    \n",
    "elif 'results' in locals() and results is not None and isinstance(results, dict):\n",
    "    # For multiple timeframe results\n",
    "    for tf, res in results.items():\n",
    "        if not res.empty:\n",
    "            tf_report = tester.generate_report(res, \"GOLD\", tf)\n",
    "            save_report(tf_report, tf)\n",
    "            \n",
    "# If all_results exists (from Option 4)\n",
    "elif 'all_results' in locals() and all_results is not None:\n",
    "    for tf, res in all_results.items():\n",
    "        if not res.empty:\n",
    "            tf_report = tester.generate_report(res, \"GOLD\", tf)\n",
    "            save_report(tf_report, tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a831851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def save_visualization(stock_symbol, timeframe):\n",
    "    \"\"\"Helper function to save a visualization to Google Drive\"\"\"\n",
    "    vis_path = f'/content/drive/MyDrive/Stock_AI_Predictor/Images/ParamTesting/{stock_symbol}_{timeframe}_parameter_test.png'\n",
    "    os.makedirs(os.path.dirname(vis_path), exist_ok=True)\n",
    "    \n",
    "    # Generate visualization again and save\n",
    "    fig = tester.visualize_results(stock_symbol, timeframe, save_path=vis_path)\n",
    "    print(f\"Visualization saved to {vis_path}\")\n",
    "    return vis_path\n",
    "\n",
    "# Save visualizations based on what data we have\n",
    "if 'results' in locals() and results is not None and not isinstance(results, dict):\n",
    "    # For single timeframe results\n",
    "    save_visualization(\"GOLD\", \"M1\")\n",
    "    \n",
    "elif 'results' in locals() and results is not None and isinstance(results, dict):\n",
    "    # For multiple timeframe results\n",
    "    for tf in results.keys():\n",
    "        save_visualization(\"GOLD\", tf)\n",
    "        \n",
    "# If all_results exists (from Option 4)\n",
    "elif 'all_results' in locals() and all_results is not None:\n",
    "    for tf in all_results.keys():\n",
    "        save_visualization(\"GOLD\", tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4735d3",
   "metadata": {},
   "source": [
    "## 7. Download Database (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60adabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the updated database to your local machine\n",
    "from google.colab import files\n",
    "files.download('/content/Stock_AI_Predictor/Data/Storage/data.db')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
